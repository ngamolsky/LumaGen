{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_STRING = \"\"\"\n",
    "This is AI News! an MVP of a service that goes thru all AI discords/Twitters/reddits and summarizes what people are talking about, so that you can keep up without the fatigue. Signing up here opts you in to the real thing when we launch it ðŸ”œ\n",
    "\n",
    "a quiet day is all you need.\n",
    "\n",
    "AI News for 9/25/2024-9/26/2024. We checked 7 subreddits, 433 Twitters and 31 Discords (224 channels, and 3282 messages) for you. Estimated reading time saved (at 200wpm): 342 minutes. You can now tag @smol_ai for AINews discussions!\n",
    "\n",
    "Many are still processing the surprise management turnover at OpenAI. Sama and gdb both posted statements. It seems the Anthropic rumors were postponed, but in the meantime the new blueberry model rumor mill is just getting started.\n",
    "\n",
    "Since it's a quiet day, you could help out AINews by checking out the RAG++ course from Weights and Biases! We featured it yesterday but forgot to include the text link. Sorry!\n",
    "\n",
    "Swyx: Something we also missed in our initial scan yesterday was chapters 6 and 7 on response synthesis and optimmization. Chapter 6 in particular is exactly what we had to do to build AINews - everything you see below is AI generated thanks to these techniques.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORYBOARD_PROMPT = \"\"\"\n",
    "You are a helpful assistant that takes a source string of news and exciting events, and returns a storyboard for a short video with content about the news. \n",
    "\n",
    "Each storyboard item should contain a description of a starting image (which we will generate based on your description), a description of the ending image (which we will also generate based on your description), and a description of the action that should happen in between\n",
    "\n",
    "SOURCE STRING:\n",
    "{source_string}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Storyboard:\n",
      "start_image_description='An animated representation of various social media logos (Discord, Twitter, Reddit) floating around a computer screen, symbolizing the gathering of information from these platforms.' end_image_description=\"The screen transitions to show the AINews logo prominently, with a call-to-action button that says 'Sign Up Now!' appearing below it.\" action='A narrator introduces AINews, explaining how it collects information from multiple AI-related platforms. The camera zooms in on the screen as it shows snippets of conversations from Discord and Twitter relating to AI news. The narrator highlights the time saved by using AINews for busy individuals who want to keep up with AI developments without the effort of scrolling through numerous posts.'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Prepare the prompt\n",
    "prompt = STORYBOARD_PROMPT.format(source_string=SOURCE_STRING)\n",
    "\n",
    "\n",
    "class Storyboard(BaseModel):\n",
    "    start_image_description: str\n",
    "    end_image_description: str\n",
    "    action: str\n",
    "\n",
    "# Call OpenAI API with GPT-4 Turbo\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "    ],\n",
    "    response_format=Storyboard\n",
    ")\n",
    "\n",
    "# Extract the generated storyboard\n",
    "storyboard = response.choices[0].message.parsed\n",
    "\n",
    "print(\"Generated Storyboard:\")\n",
    "print(storyboard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created': '2024-09-27T00:06:52.666768+00:00', 'data': [{'is_image_safe': True, 'prompt': 'An animated representation of various social media logos (Discord, Twitter, Reddit) floating around a computer screen, symbolizing the gathering of information from these platforms.', 'resolution': '1024x1024', 'seed': 1626649855, 'style_type': 'GENERAL', 'url': 'https://ideogram.ai/api/images/ephemeral/_vopFDt_R3G9eFB7IMECKA.png?exp=1727482032&sig=d3ce83dc1d177674531ebe541fb3db0821ae133168145471df324a66fb0ffb46'}]}\n",
      "{'created': '2024-09-27T00:07:12.264545+00:00', 'data': [{'is_image_safe': True, 'prompt': \"The screen transitions to show the AINews logo prominently, with a call-to-action button that says 'Sign Up Now!' appearing below it.\", 'resolution': '1024x1024', 'seed': 429542606, 'style_type': 'GENERAL', 'url': 'https://ideogram.ai/api/images/ephemeral/CVoVPjIESj6xoxoknYoTIw.png?exp=1727482051&sig=03fdfeebad6898d8e32521689f96d64a29e42de847bf974357b81721c11e5f72'}]}\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests\n",
    "IDEOGRAM_URL = \"https://api.ideogram.ai/generate\"\n",
    "\n",
    "IDEOGRAM_HEADERS = {\n",
    "    \"Api-Key\": os.getenv(\"IDEOGRAM_API_KEY\"),\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "start_image_request = {\n",
    "    \"image_request\": {\n",
    "        \"prompt\": storyboard.start_image_description,\n",
    "        \"model\": \"V_2\",\n",
    "        \"magic_prompt_option\": \"AUTO\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "start_image_response = requests.post(IDEOGRAM_URL, json=start_image_request, headers=IDEOGRAM_HEADERS)\n",
    "print(start_image_response.json())\n",
    "\n",
    "end_image_request = {\n",
    "    \"image_request\": {\n",
    "        \"prompt\": storyboard.end_image_description,\n",
    "        \"model\": \"V_2\",\n",
    "        \"magic_prompt_option\": \"AUTO\"\n",
    "    }   \n",
    "}\n",
    "\n",
    "end_image_response = requests.post(IDEOGRAM_URL, json=end_image_request, headers=IDEOGRAM_HEADERS)\n",
    "print(end_image_response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlumaai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LumaAI\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m LumaAI()\n\u001b[1;32m      5\u001b[0m generation \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mgenerations\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mstoryboard\u001b[38;5;241m.\u001b[39maction,\n\u001b[1;32m      7\u001b[0m     keyframes\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      8\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe0\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mstart_image_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m       },\n\u001b[1;32m     12\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe1\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_image_response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m       }\n\u001b[1;32m     16\u001b[0m     }\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'url'"
     ]
    }
   ],
   "source": [
    "from lumaai import LumaAI\n",
    "\n",
    "client = LumaAI()\n",
    "\n",
    "generation = client.generations.create(\n",
    "    prompt=storyboard.action,\n",
    "    keyframes={\n",
    "      \"frame0\": {\n",
    "        \"type\": \"image\",\n",
    "        \"url\": start_image_response.json()[\"data\"][0][\"url\"]\n",
    "      },\n",
    "      \"frame1\": {\n",
    "        \"type\": \"image\",\n",
    "        \"url\": end_image_response.json()[\"data\"][0][\"url\"]\n",
    "      }\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

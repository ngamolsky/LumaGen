{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_MARKDOWN = \"\"\"\n",
    "**Subject: The Wordpress vs WP Engine Drama**\n",
    "\n",
    "In a surprising twist of events, the open-source giant WordPress is entangled in a dramatic controversy surrounding its licensing policies aimed squarely at WP Engine, stirring fierce discussions across the web. **\"How can you expect any goodwill towards open-source from a community when you insist on enforcing fees?\"** This quote captures the mounting frustration many in the tech community feel as these events unfold.\n",
    "\n",
    "**Background Context**  \n",
    "WordPress, an open-source content management system, has thrived on its community-driven model for years. However, recently, the organization faced backlash due to new licensing fee structures selectively impacting WP Engine, a leading managed Wordpress host. This move has raised concerns among other hosting companies and developers about potential instability and implications for open-source projects.\n",
    "\n",
    "---\n",
    "\n",
    "**The Emergence of Tension**  \n",
    "The friction began to surface as Automattic, the parent company of WordPress, targeted WP Engine for allegedly not contributing enough to the WordPress ecosystem. **James Ivings** pointed out in one of his tweets, *“You can’t go IPO with just a happy customer base, you need to be extracting profits from the entire market (via licensing).”* This sentiment echoes the belief that the motives behind the licensing changes extend beyond simply supporting the open-source initiative. ([source](https://twitter.com/jamesivings/status/1839422193681481750))\n",
    "\n",
    "---\n",
    "\n",
    "**Mixed Reactions Among Developers**  \n",
    "As the news broke, reaction from the community was polarized. While some developers supported Automattic's actions as a means to ensure sustainable growth, others voiced concerns about stifling innovation and creating a hostile environment for open source. One developer remarked that experienced consequences, like **“Being blocked from installing plugins,”** could negatively impact WP Engine's customer base and, subsequently, WordPress's reputation as a stable and reliable platform. ([source](https://twitter.com/arvidkahl/status/1839445536686174387))\n",
    "\n",
    "---\n",
    "\n",
    "**The Financial Perspective**  \n",
    "Conversations centered around revenue models emerged, as seen in **Danny Postmaa's** reflections on his experiences, *\"more growth != more support tickets.\"* He noted that despite their expanding user base, support requests remained steady, indicating a deeper complexity in managing resources amid growth. ([source](https://twitter.com/dannypostmaa/status/1839847665338925293))\n",
    "\n",
    "There’s a growing belief that this drama could lead to significant changes in how hosting services operate with WordPress, resulting in a shift towards licensing strategies that others, like NewFoldDigital, have already embraced. Many felt securing licensing is a smart strategic move, potentially raising the licensing fees for all WP hosting partners. ([source](https://twitter.com/jessethanley/status/1839569215000588641))\n",
    "\n",
    "---\n",
    "\n",
    "**Community Support and Reactions**  \n",
    "While the turmoil has pushed various developers to share their thoughts online, there’s a palpable sense of disbelief among users and developers alike. The unforeseen changes raise questions about open-source integrity, As **Arvid Kahl** noted, emphasizing the need for transparency from Automattic in their reasoning. *“I hope the ecosystem is self-healing. I just hope WPE being blocked from installing can be healed without causing massive reputational damage,”* he expressed. ([source](https://twitter.com/arvidkahl/status/1839445536686174387))\n",
    "\n",
    "---\n",
    "\n",
    "In conclusion, the **WordPress vs. WP Engine drama** reveals not just a licensing issue but digs into the larger questions surrounding the sustainability of open-source models and the balance of growth, community trust, and corporate influence. As this saga unfolds, the tech community watches closely, ready to respond.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Optional, List, Union\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "STORYBOARD_PROMPT = \"\"\"\n",
    "I will provide you with a source string that represents a news article.\n",
    "\n",
    "Your job is to create a storyboard for a video that will be generated from the news article.\n",
    "\n",
    "The storyboard should be an array of objects, where each object represents a starting frame for a video, which will then be animated to create a video segment with a fixed duration.\n",
    "\n",
    "Don't put two of the same type in a row, and use at least one of each type.\n",
    "\n",
    "I will also supply a total duration for the video, generate enough frames to fill the duration given a duration of 2 seconds for each frame. Print out the total number of frames you will generate.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "TYPE_DESCRIPTION = {\n",
    "    \"meme\": \"a meme image, that will be animated\",\n",
    "    \"twitter_screenshot\": \"a screenshot of a twitter thread\",\n",
    "    \"stock_video\": \"a stock video based on an initial image\",\n",
    "}\n",
    "\n",
    "\n",
    "STOCK_IMAGE_DESCRIPTION = \"\"\"\n",
    "A description of an image that will be used as a prompt to generate a stock image. We want the image to be photo realistic, showing a scene that matches the source markdown in some way.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class StoryboardItem(BaseModel):\n",
    "    type: Literal[\"meme\", \"twitter_screenshot\", \"stock_video\"] = Field(\n",
    "        ..., description=str(TYPE_DESCRIPTION)\n",
    "    )\n",
    "    stock_image_description: Union[str, None] = Field(\n",
    "        ..., description=STOCK_IMAGE_DESCRIPTION\n",
    "    )\n",
    "    twitter_url: Union[str, None] = Field(\n",
    "        ...,\n",
    "        description=\"The url of the twitter thread to screenshot if the type is twitter_screenshot. Leave blank if the type is not twitter_screenshot. Make sure the tweet is in the source markdown.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class Storyboard(BaseModel):\n",
    "    items: List[StoryboardItem] = Field(..., description=\"The storyboard items\")\n",
    "    total_duration: int = Field(\n",
    "        ..., description=\"The total duration of the video in seconds\"\n",
    "    )\n",
    "    total_frames: int = Field(\n",
    "        ..., description=\"The total number of frames in the video\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "openai_client = OpenAI()\n",
    "\n",
    "TOTAL_DURATION = 40\n",
    "\n",
    "# Call OpenAI API with GPT-4 Turbo\n",
    "response = openai_client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": STORYBOARD_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": SOURCE_MARKDOWN},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"The total duration of the video is {TOTAL_DURATION} seconds.\",\n",
    "        },\n",
    "    ],\n",
    "    response_format=Storyboard,\n",
    ")\n",
    "\n",
    "# Extract the generated storyboard\n",
    "storyboard = response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "print(\"Storyboard: \")\n",
    "print(\"Duration: \", storyboard.total_duration)\n",
    "print(\"Total Frames: \", storyboard.total_frames)\n",
    "for item in storyboard.items:\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "IDEOGRAM_URL = \"https://api.ideogram.ai/generate\"\n",
    "\n",
    "IDEOGRAM_HEADERS = {\n",
    "    \"Api-Key\": os.getenv(\"IDEOGRAM_API_KEY\"),\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\n",
    "async def generate_ideo_image(prompt: str, starting_image_url: Optional[str] = None):\n",
    "    image_request = {\n",
    "        \"image_request\": {\n",
    "            \"prompt\": prompt,\n",
    "            \"model\": \"V_2\",\n",
    "            \"magic_prompt_option\": \"AUTO\",\n",
    "            \"aspect_ratio\": \"ASPECT_9_16\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if starting_image_url:\n",
    "        image_request[\"image_request\"][\"keyframe\"] = {\n",
    "            \"frame0\": {\"type\": \"image\", \"url\": starting_image_url}\n",
    "        }\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\n",
    "            IDEOGRAM_URL, json=image_request, headers=IDEOGRAM_HEADERS\n",
    "        ) as response:\n",
    "            return await response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "ACCOUNT_ID = os.environ.get('R2_ACCOUNT_ID')\n",
    "ACCESS_KEY_ID = os.environ.get('R2_ACCESS_KEY_ID') \n",
    "SECRET_ACCESS_KEY = os.environ.get('R2_SECRET_ACCESS_KEY')\n",
    "BUCKET_NAME = os.environ.get('R2_BUCKET_NAME')\n",
    "CLOUDFLARE_BUCKET_PUBLIC_URL = \"https://pub-2576bbab2f764a5a9c3fdc59f470ef1a.r2.dev\"\n",
    "\n",
    "s3_client = boto3.client('s3',\n",
    "    endpoint_url=f'https://{ACCOUNT_ID}.r2.cloudflarestorage.com',\n",
    "    aws_access_key_id=ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=SECRET_ACCESS_KEY,\n",
    "    config=Config(signature_version='s3v4')\n",
    ")\n",
    "\n",
    "async def upload_to_cloudflare(image_path):\n",
    "    try:\n",
    "        with open(image_path, 'rb') as file:\n",
    "            object_name = os.path.basename(image_path)\n",
    "            s3_client.upload_fileobj(file, BUCKET_NAME, object_name)\n",
    "\n",
    "            file_name = image_path.split('/')[-1]\n",
    "            cloudflare_url = f\"{CLOUDFLARE_BUCKET_PUBLIC_URL}/{file_name}\"\n",
    "            return cloudflare_url\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to Cloudflare R2: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweetcapture import TweetCapture\n",
    "import asyncio\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "async def capture_tweet(url, port):\n",
    "    try:\n",
    "        tweet = TweetCapture()\n",
    "        tweet.add_chrome_argument(f\"--remote-debugging-port={port}\")\n",
    "        \n",
    "        # Create 'tweets' directory if it doesn't exist\n",
    "        os.makedirs('tweets', exist_ok=True)\n",
    "        \n",
    "        # Generate a filename based on the URL and username\n",
    "        username = url.split('/')[-3]  # Assuming the URL format is twitter.com/username/status/id\n",
    "        filename = f\"tweets/{username}_{url.split('/')[-1]}.png\"\n",
    "        \n",
    "        await tweet.screenshot(url, path=filename, overwrite=True)\n",
    "\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"Error capturing tweet {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def create_backdrop(tweet_image_path, output_path):\n",
    "    tweet_image = Image.open(tweet_image_path)\n",
    "    tweet_width, tweet_height = tweet_image.size\n",
    "\n",
    "    # Add padding\n",
    "    padding = 50\n",
    "    tweet_width_padded = tweet_width + 2 * padding\n",
    "    tweet_height_padded = tweet_height + 2 * padding\n",
    "\n",
    "    # Create a 9:16 backdrop\n",
    "    backdrop_width = max(tweet_width_padded, int(tweet_height_padded * 9 / 16))\n",
    "    backdrop_height = max(tweet_height_padded, int(tweet_width_padded * 16 / 9))\n",
    "    \n",
    "    # Determine background color based on tweet image\n",
    "    tweet_colors = tweet_image.getcolors(tweet_image.size[0] * tweet_image.size[1])\n",
    "    avg_color = sum(color[0] * color[1][0] for color in tweet_colors) / sum(color[0] for color in tweet_colors)\n",
    "    bg_color = 'white' if avg_color < 128 else 'black'\n",
    "    \n",
    "    backdrop = Image.new('RGB', (backdrop_width, backdrop_height), bg_color)\n",
    "    \n",
    "    # Calculate position to center the tweet\n",
    "    x = (backdrop_width - tweet_width_padded) // 2\n",
    "    y = (backdrop_height - tweet_height_padded) // 2\n",
    "    \n",
    "    # Create a new image with padding for shadow\n",
    "    padded_tweet = Image.new('RGBA', (tweet_width_padded, tweet_height_padded), (0, 0, 0, 0))\n",
    "    \n",
    "    \n",
    "    # Paste the original tweet image\n",
    "    padded_tweet.paste(tweet_image, (padding, padding))\n",
    "    \n",
    "    # Paste the padded tweet onto the backdrop\n",
    "    backdrop.paste(padded_tweet, (x, y), padded_tweet)\n",
    "    \n",
    "    backdrop.save(output_path)\n",
    "    return output_path\n",
    "\n",
    "async def capture_tweets(tweet_urls):\n",
    "    port = 9222\n",
    "    tasks = []\n",
    "    for url in tweet_urls:\n",
    "        tasks.append(asyncio.create_task(capture_tweet(url, port)))\n",
    "        port += 1\n",
    "\n",
    "    filenames = []\n",
    "    for task in asyncio.as_completed(tasks):\n",
    "        try:\n",
    "            filename = await task\n",
    "            if filename:\n",
    "                output_filename = f\"{os.path.splitext(filename)[0]}_backdrop.png\"\n",
    "                backdrop_filename = create_backdrop(filename, output_filename)\n",
    "                url = await upload_to_cloudflare(backdrop_filename)\n",
    "                filenames.append(url)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing task: {str(e)}\")\n",
    "\n",
    "    return filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumaai import AsyncLumaAI\n",
    "import time\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "MAX_ATTEMPTS = 30\n",
    "POLL_INTERVAL = 5\n",
    "\n",
    "client = AsyncLumaAI()\n",
    "\n",
    "async def generate_luma_video(prompt: Optional[str] = None, start_image_url: Optional[str] = None, aspect_ratio: str = \"16:9\" ):\n",
    "    generation = await client.generations.create(\n",
    "        prompt=prompt,\n",
    "        keyframes={\n",
    "            \"frame0\": {\n",
    "                \"type\": \"image\",\n",
    "                \"url\": start_image_url\n",
    "            }\n",
    "        } if start_image_url else {},\n",
    "        aspect_ratio=aspect_ratio\n",
    "    )\n",
    "    return generation.id\n",
    "\n",
    "async def poll_generation(generation_id, max_attempts=MAX_ATTEMPTS, delay=POLL_INTERVAL):\n",
    "    for attempt in range(max_attempts):\n",
    "        print(f\"Attempt {attempt + 1}/{max_attempts} to poll generation {generation_id}\")\n",
    "        status = await client.generations.get(generation_id)\n",
    "        print(f\"Current status: {status.state}\")\n",
    "        if status.state == \"completed\":\n",
    "            print(f\"Generation {generation_id} completed successfully\")\n",
    "            return status\n",
    "        elif status.state == \"failed\":\n",
    "            print(f\"Generation {generation_id} failed\")\n",
    "            raise Exception(f\"Generation failed: {status.failure_reason}\")\n",
    "        \n",
    "        print(f\"Waiting {delay} seconds before next attempt\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    print(f\"Max attempts ({max_attempts}) reached for generation {generation_id}\")\n",
    "    raise Exception(\"Max attempts reached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_meme_backdrop(meme_url, backdrop_width=1080, backdrop_height=1920):\n",
    "    # Download the meme image\n",
    "    response = requests.get(meme_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    content_type = response.headers.get('Content-Type', '')\n",
    "    if not content_type.startswith('image'):\n",
    "        print(f\"The URL does not point to an image. Content-Type: {content_type}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        meme_image = Image.open(BytesIO(response.content))\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open image: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "    # Create a 9:16 aspect ratio backdrop\n",
    "    img_array = np.array(meme_image)\n",
    "    average_color = np.mean(img_array)\n",
    "    background_color = (0, 0, 0) if average_color > 128 else (255, 255, 255)\n",
    "    \n",
    "    backdrop = Image.new('RGB', (backdrop_width, backdrop_height), background_color)\n",
    "\n",
    "    # Calculate the maximum size for the meme image to fit the backdrop\n",
    "    meme_aspect_ratio = meme_image.width / meme_image.height\n",
    "    backdrop_aspect_ratio = backdrop_width / backdrop_height\n",
    "\n",
    "    if meme_aspect_ratio > backdrop_aspect_ratio:\n",
    "        # Meme is wider, fit to width\n",
    "        new_width = backdrop_width\n",
    "        new_height = int(backdrop_width / meme_aspect_ratio)\n",
    "    else:\n",
    "        # Meme is taller, fit to height\n",
    "        new_height = backdrop_height\n",
    "        new_width = int(backdrop_height * meme_aspect_ratio)\n",
    "\n",
    "    # Resize meme image to fit within the backdrop while maintaining aspect ratio\n",
    "    meme_image = meme_image.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "    # Calculate position to center the meme image\n",
    "    x = (backdrop_width - new_width) // 2\n",
    "    y = (backdrop_height - new_height) // 2\n",
    "\n",
    "    # Paste the meme image onto the backdrop\n",
    "    backdrop.paste(meme_image, (x, y))\n",
    "\n",
    "    # Save the combined image to a BytesIO object\n",
    "    combined_image_io = BytesIO()\n",
    "    backdrop.save(combined_image_io, format='PNG')\n",
    "    combined_image_io.seek(0)\n",
    "\n",
    "    # Save the combined image to the memes directory\n",
    "    \n",
    "    # Ensure the memes directory exists\n",
    "    memes_dir = 'memes'\n",
    "    os.makedirs(memes_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate a unique filename\n",
    "    import uuid\n",
    "    filename = f'meme_{uuid.uuid4()}.png'\n",
    "    filepath = os.path.join(memes_dir, filename)\n",
    "    \n",
    "    # Save the image\n",
    "    with open(filepath, 'wb') as f:\n",
    "        f.write(combined_image_io.getvalue())\n",
    "    \n",
    "    print(f\"Meme saved to: {filepath}\")\n",
    "\n",
    "    return filepath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyairtable import Api\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def process_video(item):\n",
    "    if item.type == \"twitter_screenshot\":\n",
    "        raise ValueError(\"Twitter screenshots dont make videos\")\n",
    "    elif item.type == \"stock_video\":\n",
    "        ideogram_response = await generate_ideo_image(item.stock_image_description)\n",
    "        luma_video_id = await generate_luma_video(prompt=None, \n",
    "                                            start_image_url=ideogram_response['data'][0]['url'])\n",
    "        \n",
    "    elif item.type == \"meme\":\n",
    "        dict_memes = json.dumps(reformatted_data)\n",
    "        model_response = openai_client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-2024-08-06\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Given the following memes {dict_memes}, give the closest matching meme URL to {item.stock_image_description}\"},\n",
    "            ],\n",
    "            response_format=ImageUrl,\n",
    "        )\n",
    "        meme_url = model_response.choices[0].message.parsed\n",
    "\n",
    "        print(\"meme_url\", meme_url)\n",
    "\n",
    "        meme_backdrop = create_meme_backdrop(meme_url.url)\n",
    "\n",
    "        url = await upload_to_cloudflare(meme_backdrop)\n",
    "\n",
    "\n",
    "        luma_video_id = await generate_luma_video(prompt=None, start_image_url=url)\n",
    "    result = await poll_generation(luma_video_id)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(storyboard.items[0])\n",
    "await process_video(storyboard.items[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meme_url url='https://v5.airtableusercontent.com/v3/u/33/33/1727575200000/ydC_ayEaGWeOIErF1fQqDw/kWG_RaLQe_7t9aVI4M5MqRVfBXSp-DOZsRkVRDd6s7nRfzqXonvJTe9L3Fz6RwagwnlmMn2ed5aGutWNMPvLD4a_fmsGaNPfE5yFgHN38_JvTTIMuVDWclsIgY382h9C-ayTldhJRYj1mN2QVQEylM_5Cl1q4hN8XNCOwbpRq4o/pg2YaWkYziW03lqa9aV9lXEXWwtd5cLUO_hj1paMV5I'\n",
      "Meme saved to: memes/meme_7c221654-13af-4cab-807f-1a5506d78ebc.png\n",
      "meme_url url='https://v5.airtableusercontent.com/v3/u/33/33/1727575200000/3BXBEgBfbT9aPlB_2tPsSw/rPa5Cl3A_jcBvTpeA_y5Tz2xBv1mWTgFN2xh3Wuha0o_xu1lEkacad975NnBppr7wcuMjvCP4xdSW29ih8ArC3tNbUstIIBBS49f2905Ub6sKWXHy10bSyvmDFvhAcARVIaieCqQC_oz6mqWVcaky5yWQhKR9axaAs0dYesSMcI/_z2bJH_j2YTwN_RWng8CIn9dNBmJbE1GfF6vZJ-Uios'\n",
      "Meme saved to: memes/meme_4ae380ca-0fb9-48a6-98c1-13a29af01a6f.png\n",
      "meme_url url='https://v5.airtableusercontent.com/v3/u/33/33/1727575200000/aDaNbGpGj9Ro5dDq83sBVw/GiCyVDz9V3cRV4e5ujdXUxSiGIhbHE_Er37bzVZ5OiWQB90ThG9q--02OjQgYSm6qi8d3yj8BoNk6Q3ha3MED8DGyHbi3prwQ6abF0kU50G--Y-F1hIzj4cIyIxeKXuccMAk7AnUYAGarkziSsMphA/FJJ5dsCOB5MiskKI02SZkSXh9L8ZuzGJONfURb-0hsI'\n",
      "Meme saved to: memes/meme_725ebe50-859f-448a-bf2d-14981622b371.png\n",
      "meme_url url='https://v5.airtableusercontent.com/v3/u/33/33/1727575200000/3BXBEgBfbT9aPlB_2tPsSw/rPa5Cl3A_jcBvTpeA_y5Tz2xBv1mWTgFN2xh3Wuha0o_xu1lEkacad975NnBppr7wcuMjvCP4xdSW29ih8ArC3tNbUstIIBBS49f2905Ub6sKWXHy10bSyvmDFvhAcARVIaieCqQC_oz6mqWVcaky5yWQhKR9axaAs0dYesSMcI/_z2bJH_j2YTwN_RWng8CIn9dNBmJbE1GfF6vZJ-Uios'\n",
      "Meme saved to: memes/meme_8b256cc7-9563-4bf5-9554-8d2fdba979dc.png\n",
      "meme_url url='https://v5.airtableusercontent.com/v3/u/33/33/1727575200000/zPDDzpn41fVdQwtMDgbmsA/rG1lPjTqPqTnImPhkVpzP9wmDP1dhdvx-JN0Xs1KFleq7d1xUugbVOXA-8DBpewqNTIrqBDz58e-BAlItsKtzJkyBgpAKRwNG5W-cAcnYQW6gNSbvDp5_220-tWT8TokQk_mmXM2dSJ_Z-xyacThfWu0AccPCke8Zr0eQSTKcmw/SfGjFlUBqHCJwWYJHyQtTwVsQEBCkoMLQaONWCqzWn4'\n",
      "Meme saved to: memes/meme_42e13f1c-4d24-4773-9460-09dff335637d.png\n",
      "meme_url url='https://v5.airtableusercontent.com/v3/u/33/33/1727575200000/kx6KEBaWjp-dEq0Evf33Dw/WIkbHn_I5Ok-3mR52oIfy7PdbYfFOoTmaPFqoEQul5NlnFim0TpP-OXEsUoe7q94ENDSQ5zUYVU6J5QD22w3auzFvRi8-4zhShyZ_tUh3KXW1OhU2G-oaatqkV1aaPFv2XJ_rd-MQGdezu3XQWNkb9-Q2ldN3ah4ZyNkXwl9Xtw/8HuR3afKDlZ-E0h74do2Rls0AmkOxKkCpT58Ypm2rN8'\n",
      "Meme saved to: memes/meme_c145f2ca-8f1c-4604-8d74-50ac5c1f3942.png\n",
      "meme_url url='https://v5.airtableusercontent.com/v3/u/33/33/1727575200000/3BXBEgBfbT9aPlB_2tPsSw/rPa5Cl3A_jcBvTpeA_y5Tz2xBv1mWTgFN2xh3Wuha0o_xu1lEkacad975NnBppr7wcuMjvCP4xdSW29ih8ArC3tNbUstIIBBS49f2905Ub6sKWXHy10bSyvmDFvhAcARVIaieCqQC_oz6mqWVcaky5yWQhKR9axaAs0dYesSMcI/_z2bJH_j2YTwN_RWng8CIn9dNBmJbE1GfF6vZJ-Uios'\n",
      "Meme saved to: memes/meme_c0262a27-7d0b-4481-b880-785768e45ece.png\n",
      "Attempt 1/30 to poll generation 153c601c-3870-4854-b4a0-f933f2447bb5\n",
      "Attempt 1/30 to poll generation eb52d39c-c6f6-4a75-ad15-8d472c43be06\n",
      "Attempt 1/30 to poll generation 671d521f-affa-459e-b6c4-ce1fedcaa665\n",
      "Attempt 1/30 to poll generation 88ebdfbf-0c02-4df9-9075-8380f5ba2c85\n",
      "Attempt 1/30 to poll generation 19e71962-0315-41a6-92b7-5654026d8323\n",
      "Attempt 1/30 to poll generation ec312d6c-1ba4-4fcf-9bef-2c41e3e864de\n",
      "Current status: dreaming\n",
      "Waiting 5 seconds before next attempt\n",
      "Attempt 2/30 to poll generation 153c601c-3870-4854-b4a0-f933f2447bb5\n",
      "Current status: dreaming\n",
      "Waiting 5 seconds before next attempt\n",
      "Attempt 2/30 to poll generation eb52d39c-c6f6-4a75-ad15-8d472c43be06\n",
      "Attempt 1/30 to poll generation d13e7044-750f-4adf-b41c-7cae8157a3fc\n",
      "Error capturing tweet https://twitter.com/dannypostmaa/status/1839847665338925293: Tweets not found\n",
      "Current status: dreaming\n",
      "Waiting 5 seconds before next attempt\n",
      "Attempt 2/30 to poll generation d13e7044-750f-4adf-b41c-7cae8157a3fc\n",
      "Current status: dreaming\n",
      "Waiting 5 seconds before next attempt\n",
      "Attempt 2/30 to poll generation 671d521f-affa-459e-b6c4-ce1fedcaa665\n",
      "Current status: dreaming\n",
      "Waiting 5 seconds before next attempt\n",
      "Attempt 3/30 to poll generation d13e7044-750f-4adf-b41c-7cae8157a3fc\n",
      "Current status: dreaming\n",
      "Waiting 5 seconds before next attempt\n",
      "Attempt 3/30 to poll generation 153c601c-3870-4854-b4a0-f933f2447bb5\n",
      "Attempt 1/30 to poll generation 2d30cfb9-487e-4568-bca8-77876bbf4b15\n",
      "Attempt 1/30 to poll generation 67a8a376-42a5-4e93-8d67-68f8a71a46de\n",
      "Attempt 1/30 to poll generation 7823b0da-acb1-4d2b-8bf1-063cdc16abfb\n",
      "Attempt 1/30 to poll generation 54da52ac-ccdc-4279-8a29-3629b216e0bb\n",
      "Attempt 1/30 to poll generation a94d04dc-b739-420b-8126-736771303d6c\n",
      "Attempt 1/30 to poll generation 8850b602-a89c-4f0d-b1bc-546d83d7eb33\n",
      "Current status: dreaming\n",
      "Waiting 5 seconds before next attempt\n",
      "Attempt 2/30 to poll generation a94d04dc-b739-420b-8126-736771303d6c\n",
      "Current status: dreaming\n",
      "Waiting 5 seconds before next attempt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from combine_clips import combine_clips\n",
    "\n",
    "def clear_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "async def fetch_all_resources(processed_items):\n",
    "    tweet_urls = [item.twitter_url for item in processed_items if item.type == 'twitter_screenshot']\n",
    "    image_items = [item for item in processed_items if item.type in ['stock_video', 'meme']]\n",
    "\n",
    "    tweet_tasks = [capture_tweets(tweet_urls)] if tweet_urls else []\n",
    "    image_tasks = [process_video(item) for item in image_items]\n",
    "    results = await asyncio.gather(*tweet_tasks, *image_tasks)\n",
    "\n",
    "    tweet_files = results[0] if tweet_urls else []\n",
    "    video_results = results[1:] if image_items else []\n",
    "\n",
    "    return tweet_files, video_results\n",
    "\n",
    "async def main():\n",
    "    tweet_files, video_results = await fetch_all_resources(storyboard.items)\n",
    "\n",
    "\n",
    "    combined_resources = []\n",
    "\n",
    "    tweet_index = 0\n",
    "    image_index = 0\n",
    "\n",
    "    for item in storyboard.items:\n",
    "        if item.type == 'twitter_screenshot' :\n",
    "\n",
    "            tweet_id = item.twitter_url.split(\"/\")[-1]\n",
    "  \n",
    "            if any(tweet_id in tweet_file for tweet_file in tweet_files):\n",
    "                url = tweet_files[tweet_index]\n",
    "               \n",
    "                combined_resources.append({\n",
    "                    \"type\": \"image\",\n",
    "                    \"url\": url,\n",
    "                    \"duration\": 2\n",
    "                })\n",
    "                tweet_index += 1\n",
    "        elif item.type in ['stock_video', 'meme']:\n",
    "            combined_resources.append({\n",
    "                \"type\": \"video\",\n",
    "                \"url\": video_results[image_index].assets.video,\n",
    "                \"duration\": 2\n",
    "            })\n",
    "            image_index += 1\n",
    "\n",
    "    print(\"Combined resources in storyboard order:\")\n",
    "    print(combined_resources)\n",
    "\n",
    "\n",
    "    memes_dir = 'memes'\n",
    "    tweets_dir = 'tweets'\n",
    "\n",
    "    if os.path.exists(memes_dir):\n",
    "        clear_directory(memes_dir)\n",
    "        print(f\"Cleared contents of {memes_dir} directory\")\n",
    "    else:\n",
    "        print(f\"{memes_dir} directory does not exist\")\n",
    "\n",
    "    if os.path.exists(tweets_dir):\n",
    "        clear_directory(tweets_dir)\n",
    "        print(f\"Cleared contents of {tweets_dir} directory\")\n",
    "    else:\n",
    "        print(f\"{tweets_dir} directory does not exist\")\n",
    "    return combined_resources\n",
    "\n",
    "combined_resources = await main()\n",
    "combine_clips(combined_resources, \"output.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "for resource in combined_resources:\n",
    "    if resource[\"type\"] == \"image\":\n",
    "        print(resource[\"url\"])\n",
    "        display(Image(url=resource[\"url\"]))\n",
    "    elif resource[\"type\"] == \"video\":\n",
    "        print(resource[\"url\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

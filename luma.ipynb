{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_STRING = \"\"\"\n",
    "Advanced Voice Model Release\n",
    "\n",
    "OpenAI is rolling out an advanced voice model for ChatGPT Plus and Team users over the course of a week.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORYBOARD_PROMPT = \"\"\"\n",
    "You are a helpful assistant that takes a source string of news and exciting events, and returns a storyboard for a short video with content about the news. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Image Description:\n",
      "A vibrant tech office with engineers working on computers, showcasing screens with code, voice waveforms, and the OpenAI logo prominently displayed.\n",
      "Action:\n",
      "The video starts with a busy tech office where engineers are collaborating on the new voice model. As they discuss, visuals of voice waveforms animate alongside text detailing the features and benefits of the advanced voice model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "ACTION_DESCRIPTION = \"\"\"\n",
    "Action Guidelines:\n",
    "\n",
    "Keep the actions simple and concise. No more than 2 sentences.\n",
    "\n",
    "\n",
    "1. **Be Specific:** Clearly describe the main subject, setting, and any key elements you want in the video.\n",
    "    - Example: \"A serene beach at sunset with waves gently crashing on the shore and seagulls flying in the sky.\"\n",
    "2. **Include Details:** Mention any particular details that are important for the video.\n",
    "    - Example: \"The beach has golden sand and a few palm trees. The sky is painted with hues of pink and orange.\"\n",
    "3. **Focus on Emotions or Atmosphere:** Describe the mood or atmosphere you want to convey.\n",
    "    - Example: \"The video should feel peaceful and calming.‚Äù\n",
    "4. **Use Simple Language:** Avoid complex terms and jargon. Simple, straightforward language is most effective.\n",
    "    - Example: \"A cozy living room with a crackling fireplace and a cat sleeping on the rug.\"\n",
    "\n",
    "By following these steps, you can create effective prompts that help the AI generate high-quality videos that align with your vision.\n",
    "\"\"\"\n",
    "\n",
    "class Storyboard(BaseModel):\n",
    "    start_image_description: str = Field(..., description=\"A description of the starting image. Make it representative of the news.\")\n",
    "    # end_image_description: Optional[str] = Field(None, description=\"A description of the ending image, if it makes sense to animate to an image\")\n",
    "    action: str = Field(..., description=ACTION_DESCRIPTION)\n",
    "\n",
    "# Call OpenAI API with GPT-4 Turbo\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[  \n",
    "        {\"role\": \"system\", \"content\": STORYBOARD_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": SOURCE_STRING}\n",
    "    ],\n",
    "    response_format=Storyboard\n",
    ")\n",
    "\n",
    "# Extract the generated storyboard\n",
    "storyboard = response.choices[0].message.parsed\n",
    "\n",
    "print(\"Starting Image Description:\")\n",
    "print(storyboard.start_image_description)\n",
    "\n",
    "# if storyboard.end_image_description:\n",
    "#     print(\"Ending Image Description:\")\n",
    "#     print(storyboard.end_image_description)\n",
    "\n",
    "print(\"Action:\")\n",
    "print(storyboard.action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created': '2024-09-27T04:42:48.559185+00:00', 'data': [{'is_image_safe': True, 'prompt': 'A photo of a tech office with several engineers working at their desks. The engineers are typing on their keyboards and are intently focused on their screens. The screens display various code, voice waveforms, and the OpenAI logo. The office has a modern design with a mix of wooden and metal furniture, green plants, and hanging lights.', 'resolution': '1024x1024', 'seed': 1685841975, 'style_type': 'GENERAL', 'url': 'https://ideogram.ai/api/images/ephemeral/5occ11irQ9S8EVsLeYAjrQ.png?exp=1727498588&sig=041946d7909ba21afb8f9331d295a6138f9e5f76f5c7d962e53c1446cb3e967d'}]}\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests\n",
    "IDEOGRAM_URL = \"https://api.ideogram.ai/generate\"\n",
    "\n",
    "IDEOGRAM_HEADERS = {\n",
    "    \"Api-Key\": os.getenv(\"IDEOGRAM_API_KEY\"),\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "start_image_request = {\n",
    "    \"image_request\": {\n",
    "        \"prompt\": storyboard.start_image_description,\n",
    "        \"model\": \"V_2\",\n",
    "        \"magic_prompt_option\": \"AUTO\"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "start_image_response = requests.post(IDEOGRAM_URL, json=start_image_request, headers=IDEOGRAM_HEADERS)\n",
    "print(start_image_response.json())\n",
    "\n",
    "# if storyboard.end_image_description:\n",
    "#     end_image_request = {\n",
    "#         \"image_request\": {\n",
    "#             \"prompt\": storyboard.end_image_description,\n",
    "#         \"model\": \"V_2\",\n",
    "#         \"magic_prompt_option\": \"AUTO\"\n",
    "#     }   \n",
    "# }\n",
    "\n",
    "#     end_image_response = requests.post(IDEOGRAM_URL, json=end_image_request, headers=IDEOGRAM_HEADERS)\n",
    "#     print(end_image_response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation started for prompt:  The video starts with a busy tech office where engineers are collaborating on the new voice model. As they discuss, visuals of voice waveforms animate alongside text detailing the features and benefits of the advanced voice model.\n",
      "dc4a3ff7-5cae-4d94-b126-756623463669\n"
     ]
    }
   ],
   "source": [
    "from lumaai import LumaAI\n",
    "\n",
    "client = LumaAI()\n",
    "\n",
    "generation = client.generations.create(\n",
    "    prompt=storyboard.action,\n",
    "    keyframes={\n",
    "      \"frame0\": {\n",
    "        \"type\": \"image\",\n",
    "        \"url\": start_image_response.json()[\"data\"][0][\"url\"]\n",
    "      },\n",
    "      \n",
    "      # \"frame1\": {\n",
    "      #   \"type\": \"image\",\n",
    "      #   \"url\": end_image_response.json()[\"data\"][0][\"url\"]\n",
    "      # } if storyboard.end_image_description else None\n",
    "    },\n",
    "    loop=True,\n",
    ")\n",
    "\n",
    "print(\"Generation started for prompt: \", storyboard.action)\n",
    "print(generation.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation in progress... (Attempt 1/30)\n",
      "Generation in progress... (Attempt 2/30)\n",
      "Generation in progress... (Attempt 3/30)\n",
      "Generation in progress... (Attempt 4/30)\n",
      "Generation in progress... (Attempt 5/30)\n",
      "Generation in progress... (Attempt 6/30)\n",
      "Generation in progress... (Attempt 7/30)\n",
      "Generation in progress... (Attempt 8/30)\n",
      "Generation completed successfully in 83.03 seconds!\n",
      "Result URL: Assets(video='https://storage.cdn-luma.com/dream_machine/596e160c-4954-427e-ae7d-9a65068f039c/68043563-4d6d-4018-8ed2-1f586f305132_raw_video_0.mp4_video0668a588ccbea4b289c306e6d1c0c1cfc.mp4')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def poll_generation(generation_id, max_attempts=30, delay=10):\n",
    "    start_time = time.time()\n",
    "    for attempt in range(max_attempts):\n",
    "        status = client.generations.get(generation_id)\n",
    "        if status.state == \"completed\":\n",
    "            end_time = time.time()\n",
    "            return status, end_time - start_time\n",
    "        elif status.state == \"failed\":\n",
    "            raise Exception(f\"Generation failed: {status.failure_reason}\")\n",
    "        print(f\"Generation in progress... (Attempt {attempt + 1}/{max_attempts})\")\n",
    "        time.sleep(delay)\n",
    "    raise Exception(\"Generation timed out\")\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    result, generation_time = poll_generation(generation.id)\n",
    "    print(f\"Generation completed successfully in {generation_time:.2f} seconds!\")\n",
    "    print(f\"Result URL: {result.assets}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "luma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
